#!/usr/bin/env python3
"""
LTX-2 å®Œæ•´åŠŸèƒ½æµ‹è¯• - SSH ç‰ˆæœ¬
ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼šä¸»æ¨¡å‹ + 3ä¸ªLoRA
"""
import json
import time
import random
from urllib import request
import os

BASE_URL = "http://localhost:8188"

def upload_file(filepath):
    filename = os.path.basename(filepath)
    print(f"ğŸ“¤ ä¸Šä¼  {filename}...")
    with open(filepath, 'rb') as f:
        data = f.read()
    boundary = 'Boundary' + ''.join(random.choices('0123456789', k=16))
    body = (
        f'--{boundary}\r\n'
        f'Content-Disposition: form-data; name="image"; filename="{filename}"\r\n'
        f'Content-Type: application/octet-stream\r\n\r\n'
    ).encode() + data + f'\r\n--{boundary}--\r\n'.encode()
    req = request.Request(f"{BASE_URL}/upload/image", data=body,
        headers={'Content-Type': f'multipart/form-data; boundary={boundary}'})
    with request.urlopen(req, timeout=30) as resp:
        result = json.loads(resp.read())
        print(f"   âœ… {result.get('name')}")
        return result.get('name')

def monitor_progress(prompt_id):
    """ç›‘æ§ç”Ÿæˆè¿›åº¦"""
    print("\nğŸ“Š ç›‘æ§ç”Ÿæˆè¿›åº¦...")
    last_status = None
    while True:
        try:
            req = request.Request(f"{BASE_URL}/history/{prompt_id}")
            with request.urlopen(req, timeout=5) as resp:
                history = json.loads(resp.read())
                if prompt_id in history:
                    status_info = history[prompt_id]
                    if 'outputs' in status_info and status_info['outputs']:
                        print("\nâœ… ç”Ÿæˆå®Œæˆ!")
                        return status_info
                    status = status_info.get('status', {})
                    if status != last_status:
                        print(f"   çŠ¶æ€: {status}")
                        last_status = status
        except:
            pass

        # æ£€æŸ¥é˜Ÿåˆ—
        try:
            req = request.Request(f"{BASE_URL}/queue")
            with request.urlopen(req, timeout=5) as resp:
                queue = json.loads(resp.read())
                running = len(queue.get('queue_running', []))
                pending = len(queue.get('queue_pending', []))
                if running == 0 and pending == 0:
                    time.sleep(5)  # ç­‰å¾…è¾“å‡ºå†™å…¥
                    return None
                print(f"   é˜Ÿåˆ—: è¿è¡Œä¸­={running}, ç­‰å¾…ä¸­={pending}", end='\r')
        except:
            pass

        time.sleep(3)

def main():
    print("=" * 70)
    print("LTX-2 å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("ä¸»æ¨¡å‹ + 3ä¸ªLoRA + éŸ³é¢‘é©±åŠ¨è§†é¢‘ç”Ÿæˆ")
    print("=" * 70)

    # ä¸Šä¼ æ–‡ä»¶
    print("\nğŸ“ æ­¥éª¤ 1/3: ä¸Šä¼ æµ‹è¯•æ–‡ä»¶...")
    image_name = upload_file('/workspace/ltx_test/test_input.jpg')
    audio_name = upload_file('/workspace/ltx_test/test_audio.mp3')

    # åˆ›å»ºå·¥ä½œæµ
    print("\nğŸ”§ æ­¥éª¤ 2/3: åˆ›å»ºå®Œæ•´å·¥ä½œæµ...")
    print("   ğŸ“¦ ä¸»æ¨¡å‹: ltx-2-19b-dev-fp8.safetensors (26GB)")
    print("   ğŸ“¦ LoRA 1: Distilled (å¼ºåº¦ 0.6)")
    print("   ğŸ“¦ LoRA 2: Detailer (å¼ºåº¦ 1.0)")
    print("   ğŸ“¦ LoRA 3: Camera Control (å¼ºåº¦ 0.5)")
    print("   ğŸµ éŸ³é¢‘: 5ç§’ç‰‡æ®µ")
    print("   ğŸ–¼ï¸  å›¾ç‰‡: 768x512 (è‡ªåŠ¨è°ƒæ•´)")
    print("   ğŸ¬ è¾“å‡º: 121å¸§ @ 24fps (~5ç§’è§†é¢‘)")

    seed = random.randint(0, 2**48)

    workflow = {
        "1": {
            "inputs": {"ckpt_name": "ltx-2-19b-dev-fp8.safetensors"},
            "class_type": "CheckpointLoaderSimple"
        },
        "2": {
            "inputs": {
                "lora_name": "ltx-2-19b-distilled-lora-384.safetensors",
                "strength_model": 0.6,
                "model": ["1", 0]
            },
            "class_type": "LoraLoaderModelOnly"
        },
        "3": {
            "inputs": {
                "lora_name": "ltx-2-19b-ic-lora-detailer.safetensors",
                "strength_model": 1.0,
                "model": ["2", 0]
            },
            "class_type": "LoraLoaderModelOnly"
        },
        "4": {
            "inputs": {
                "lora_name": "ltx-2-19b-lora-camera-control-dolly-in.safetensors",
                "strength_model": 0.5,
                "model": ["3", 0]
            },
            "class_type": "LoraLoaderModelOnly"
        },
        "5": {
            "inputs": {"image": image_name},
            "class_type": "LoadImage"
        },
        "6": {
            "inputs": {"audio": audio_name},
            "class_type": "LoadAudio"
        },
        "7": {
            "inputs": {
                "audio": ["6", 0],
                "max_duration": 10,
                "duration": 5,
                "start_index": 0
            },
            "class_type": "TrimAudioDuration"
        },
        "8": {
            "inputs": {"ckpt_name": "ltx-2-19b-dev-fp8.safetensors"},
            "class_type": "LTXVAudioVAELoader"
        },
        "9": {
            "inputs": {
                "audio": ["7", 0],
                "audio_vae": ["8", 0]
            },
            "class_type": "LTXVAudioVAEEncode"
        },
        "10": {
            "inputs": {
                "image": ["5", 0],
                "width": 768,
                "height": 512,
                "upscale_method": "lanczos",
                "keep_proportion": "pad",
                "pad_color": "0, 0, 0",
                "crop_position": "center",
                "divisible_by": 32
            },
            "class_type": "ImageResizeKJv2"
        },
        "11": {
            "inputs": {
                "image": ["10", 0],
                "img_compression": 35
            },
            "class_type": "LTXVPreprocess"
        },
        "12": {
            "inputs": {
                "width": 768,
                "height": 512,
                "length": 121,
                "batch_size": 1
            },
            "class_type": "EmptyLTXVLatentVideo"
        },
        "13": {
            "inputs": {
                "vae": ["1", 2],
                "image": ["11", 0],
                "latent": ["12", 0],
                "strength": 1.0,
                "bypass": False
            },
            "class_type": "LTXVImgToVideoInplace"
        },
        "14": {
            "inputs": {
                "value": 0,
                "width": 768,
                "height": 512
            },
            "class_type": "SolidMask"
        },
        "15": {
            "inputs": {
                "samples": ["9", 0],
                "mask": ["14", 0]
            },
            "class_type": "SetLatentNoiseMask"
        },
        "16": {
            "inputs": {
                "video_latent": ["13", 0],
                "audio_latent": ["15", 0]
            },
            "class_type": "LTXVConcatAVLatent"
        },
        "17": {
            "inputs": {
                "seed": seed,
                "steps": 20,
                "cfg": 1.5,
                "sampler_name": "euler",
                "scheduler": "simple",
                "denoise": 1.0,
                "model": ["4", 0],
                "positive": ["16", 0],
                "negative": ["16", 0],
                "latent_image": ["16", 0]
            },
            "class_type": "KSampler"
        },
        "18": {
            "inputs": {"av_latent": ["17", 0]},
            "class_type": "LTXVSeparateAVLatent"
        },
        "19": {
            "inputs": {
                "tile_size": 512,
                "overlap": 64,
                "temporal_size": 4096,
                "temporal_overlap": 8,
                "samples": ["18", 0],
                "vae": ["1", 2]
            },
            "class_type": "VAEDecodeTiled"
        },
        "20": {
            "inputs": {
                "frame_rate": 24,
                "loop_count": 0,
                "filename_prefix": "ltx2_full_test",
                "format": "video/h264-mp4",
                "images": ["19", 0],
                "audio": ["7", 0]
            },
            "class_type": "VHS_VideoCombine"
        }
    }

    # æäº¤å·¥ä½œæµ
    print("\nğŸš€ æ­¥éª¤ 3/3: æäº¤å¹¶ç”Ÿæˆ...")
    payload = {"prompt": workflow, "client_id": f"full_test_{int(time.time())}"}
    req = request.Request(f"{BASE_URL}/prompt",
        data=json.dumps(payload).encode(),
        headers={'Content-Type': 'application/json'})

    try:
        with request.urlopen(req, timeout=30) as resp:
            result = json.loads(resp.read())
            if 'error' in result:
                print(f"\nâŒ å·¥ä½œæµé”™è¯¯:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return None

            prompt_id = result.get('prompt_id')
            print(f"âœ… å·¥ä½œæµå·²æäº¤! ID: {prompt_id}")
            print("\n" + "=" * 70)

            # ç›‘æ§è¿›åº¦
            result = monitor_progress(prompt_id)

            if result:
                print("\nğŸ“ æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶...")
                import subprocess
                files = subprocess.check_output(
                    "ls -lt /workspace/ComfyUI/output/*.mp4 2>/dev/null | head -5",
                    shell=True
                ).decode()
                print(files)

                print("\n" + "=" * 70)
                print("ğŸ‰ è§†é¢‘ç”Ÿæˆå®Œæˆ!")
                print("=" * 70)
                print("\nğŸ“‚ è¾“å‡ºç›®å½•: /workspace/ComfyUI/output/")
                print("ğŸ¬ æ–‡ä»¶å: ltx2_full_test_*.mp4")

                return prompt_id
            else:
                print("\nâš ï¸  ç”Ÿæˆå¯èƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
                return None

    except request.HTTPError as e:
        error_body = e.read().decode('utf-8')
        print(f"\nâŒ HTTP é”™è¯¯ {e.code}")
        try:
            print(json.dumps(json.loads(error_body), indent=2, ensure_ascii=False))
        except:
            print(error_body)
        return None
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
