k#!/usr/bin/env python3
"""
LTX-2 720P æµ‹è¯• - æœ€ç»ˆç”Ÿäº§é…ç½®
1280x736, img_compression=30, é«˜è´¨é‡é¦–å¸§
"""
import json
import time
import random
from urllib import request
import os

BASE_URL = "http://localhost:8188"

def upload_file(filepath):
    filename = os.path.basename(filepath)
    print(f"ğŸ“¤ ä¸Šä¼  {filename}...")
    with open(filepath, 'rb') as f:
        data = f.read()
    boundary = 'Boundary' + ''.join(random.choices('0123456789', k=16))
    body = (
        f'--{boundary}\r\n'
        f'Content-Disposition: form-data; name="image"; filename="{filename}"\r\n'
        f'Content-Type: application/octet-stream\r\n\r\n'
    ).encode() + data + f'\r\n--{boundary}--\r\n'.encode()
    req = request.Request(f"{BASE_URL}/upload/image", data=body,
        headers={'Content-Type': f'multipart/form-data; boundary={boundary}'})
    with request.urlopen(req, timeout=30) as resp:
        result = json.loads(resp.read())
        print(f"   âœ… {result.get('name')}")
        return result.get('name')

def main():
    print("=" * 70)
    print("LTX-2 720P æœ€ç»ˆç”Ÿäº§é…ç½®æµ‹è¯•")
    print("1280x736 + img_compression=30 + é«˜è´¨é‡é¦–å¸§")
    print("=" * 70)

    print("\nğŸ“ æ­¥éª¤ 1/3: ä¸Šä¼ æ–‡ä»¶...")
    image_name = upload_file('/workspace/ltx_test/test_input.jpg')
    audio_name = upload_file('/workspace/ltx_test/test_audio.mp3')

    print("\nğŸ”§ æ­¥éª¤ 2/3: åˆ›å»º720På·¥ä½œæµ...")
    print("   ğŸ“¦ CheckpointLoaderSimple: ltx-2-19b-dev-fp8.safetensors")
    print("   ğŸ“ LTXAVTextEncoderLoader: gemma_3_12B_it_fp8_scaled.safetensors")
    print("   ğŸ“¦ 3ä¸ª LoRA æ¨¡å‹ (Distilled 0.6 + Detailer 1.0 + Camera 0.5)")
    print("   ğŸµ éŸ³é¢‘: 10ç§’å®Œæ•´")
    print("   ğŸ–¼ï¸  å›¾ç‰‡: 1280x736 (720P), img_compression=30 (é«˜è´¨é‡)")
    print("   ğŸ¬ è¾“å‡º: 297å¸§ @ 30fps = 9.9ç§’")
    print("   âš™ï¸  é‡‡æ ·: 8æ­¥ + CFG 1.0")
    print("   ğŸ’¾ VAE: tile_size=640, overlap=80")

    seed = random.randint(0, 2**48)

    workflow = {
        "184": {
            "inputs": {"ckpt_name": "ltx-2-19b-dev-fp8.safetensors"},
            "class_type": "CheckpointLoaderSimple"
        },
        "155": {
            "inputs": {
                "text_encoder": "gemma_3_12B_it_fp8_scaled.safetensors",
                "ckpt_name": "ltx-2-19b-dev-fp8.safetensors",
                "device": "default"
            },
            "class_type": "LTXAVTextEncoderLoader"
        },
        "171": {
            "inputs": {"ckpt_name": "ltx-2-19b-dev-fp8.safetensors"},
            "class_type": "LTXVAudioVAELoader"
        },
        "288": {
            "inputs": {
                "lora_name": "ltx-2-19b-distilled-lora-384.safetensors",
                "strength_model": 0.6,
                "model": ["184", 0]
            },
            "class_type": "LoraLoaderModelOnly"
        },
        "290": {
            "inputs": {
                "lora_name": "ltx-2-19b-ic-lora-detailer.safetensors",
                "strength_model": 1.0,
                "model": ["288", 0]
            },
            "class_type": "LoraLoaderModelOnly"
        },
        "289": {
            "inputs": {
                "lora_name": "ltx-2-19b-lora-camera-control-dolly-in.safetensors",
                "strength_model": 0.5,
                "model": ["290", 0]
            },
            "class_type": "LoraLoaderModelOnly"
        },
        "240": {
            "inputs": {"image": image_name, "upload": "image"},
            "class_type": "LoadImage"
        },
        "243": {
            "inputs": {"audio": audio_name},
            "class_type": "LoadAudio"
        },
        "244": {
            "inputs": {
                "audio": ["243", 0],
                "max_duration": 15,
                "duration": 10,
                "start_index": 0
            },
            "class_type": "TrimAudioDuration"
        },
        "241": {
            "inputs": {
                "image": ["240", 0],
                "width": 1280,
                "height": 736,
                "upscale_method": "lanczos",
                "keep_proportion": "pad",
                "pad_color": "0, 0, 0",
                "crop_position": "center",
                "divisible_by": 32
            },
            "class_type": "ImageResizeKJv2"
        },
        "269": {
            "inputs": {
                "image": ["241", 0],
                "img_compression": 30
            },
            "class_type": "LTXVPreprocess"
        },
        "162": {
            "inputs": {
                "width": 1280,
                "height": 736,
                "length": 297,
                "batch_size": 1
            },
            "class_type": "EmptyLTXVLatentVideo"
        },
        "239": {
            "inputs": {
                "vae": ["184", 2],
                "image": ["269", 0],
                "latent": ["162", 0],
                "strength": 1.0,
                "bypass": False
            },
            "class_type": "LTXVImgToVideoInplace"
        },
        "242": {
            "inputs": {
                "audio": ["244", 0],
                "audio_vae": ["171", 0]
            },
            "class_type": "LTXVAudioVAEEncode"
        },
        "249": {
            "inputs": {"value": 0, "width": 1280, "height": 736},
            "class_type": "SolidMask"
        },
        "248": {
            "inputs": {
                "samples": ["242", 0],
                "mask": ["249", 0]
            },
            "class_type": "SetLatentNoiseMask"
        },
        "166": {
            "inputs": {
                "video_latent": ["239", 0],
                "audio_latent": ["248", 0]
            },
            "class_type": "LTXVConcatAVLatent"
        },
        "169": {
            "inputs": {
                "text": "A person speaks naturally with perfect lip synchronization, high quality, detailed",
                "clip": ["155", 0]
            },
            "class_type": "CLIPTextEncode"
        },
        "165": {
            "inputs": {
                "text": "static, bad teeth, blurry, low quality, pixelated, compressed",
                "clip": ["155", 0]
            },
            "class_type": "CLIPTextEncode"
        },
        "164": {
            "inputs": {
                "frame_rate": 30,
                "positive": ["169", 0],
                "negative": ["165", 0]
            },
            "class_type": "LTXVConditioning"
        },
        "178": {
            "inputs": {"noise_seed": seed, "randomize": "disable"},
            "class_type": "RandomNoise"
        },
        "154": {
            "inputs": {"sampler_name": "euler"},
            "class_type": "KSamplerSelect"
        },
        "238": {
            "inputs": {
                "scheduler": "simple",
                "steps": 8,
                "denoise": 1.0,
                "model": ["289", 0]
            },
            "class_type": "BasicScheduler"
        },
        "153": {
            "inputs": {
                "cfg": 1.0,
                "model": ["289", 0],
                "positive": ["164", 0],
                "negative": ["164", 1]
            },
            "class_type": "CFGGuider"
        },
        "161": {
            "inputs": {
                "noise": ["178", 0],
                "guider": ["153", 0],
                "sampler": ["154", 0],
                "sigmas": ["238", 0],
                "latent_image": ["166", 0]
            },
            "class_type": "SamplerCustomAdvanced"
        },
        "245": {
            "inputs": {"av_latent": ["161", 0]},
            "class_type": "LTXVSeparateAVLatent"
        },
        "234": {
            "inputs": {
                "tile_size": 640,
                "overlap": 80,
                "temporal_size": 4096,
                "temporal_overlap": 8,
                "samples": ["245", 0],
                "vae": ["184", 2]
            },
            "class_type": "VAEDecodeTiled"
        },
        "190": {
            "inputs": {
                "frame_rate": 30,
                "loop_count": 0,
                "filename_prefix": "LTX2_720P",
                "format": "video/h264-mp4",
                "pix_fmt": "yuv420p",
                "crf": 19,
                "save_metadata": True,
                "trim_to_audio": False,
                "pingpong": False,
                "save_output": True,
                "images": ["234", 0],
                "audio": ["244", 0]
            },
            "class_type": "VHS_VideoCombine"
        }
    }

    print("\nğŸš€ æ­¥éª¤ 3/3: æäº¤å·¥ä½œæµ...")
    payload = {"prompt": workflow, "client_id": f"720p_test_{int(time.time())}"}
    req = request.Request(f"{BASE_URL}/prompt",
        data=json.dumps(payload).encode(),
        headers={'Content-Type': 'application/json'})

    try:
        with request.urlopen(req, timeout=30) as resp:
            result = json.loads(resp.read())
            if 'error' in result:
                print(f"\nâŒ é”™è¯¯:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return None

            prompt_id = result.get('prompt_id')
            print(f"âœ… å·²æäº¤! ID: {prompt_id}")
            print("\n" + "=" * 70)
            print("ğŸ¬ 720P é«˜è´¨é‡è§†é¢‘ç”Ÿæˆä¸­...")
            print("=" * 70)
            print(f"\nâ±ï¸  é¢„è®¡: ~5-7åˆ†é’Ÿ")
            print(f"ğŸ“ è¾“å‡º: /workspace/ComfyUI/output/LTX2_720P_*.mp4")
            print(f"ğŸ¯ åˆ†è¾¨ç‡: 1280x736 (720Pæ ‡å‡†)")
            print(f"ğŸ’¾ é¢„è®¡å¤§å°: 4-5MB (é«˜è´¨é‡)")
            print(f"\nâš ï¸  å…³é”®éªŒè¯ç‚¹:")
            print(f"   - å£å‹åŒæ­¥ (img_compression=30)")
            print(f"   - é¦–å¸§æ¸…æ™°åº¦")
            print(f"   - æ•´ä½“ç»†èŠ‚ä¿ç•™")
            print("\n" + "=" * 70)

            return prompt_id

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
