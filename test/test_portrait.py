#!/usr/bin/env python3
"""
LTX-2 ç«–å±æµ‹è¯• - 736x1280
"""
import json
import time
import random
from urllib import request
import os

BASE_URL = "http://localhost:8188"

def upload_file(filepath):
    filename = os.path.basename(filepath)
    print(f"ğŸ“¤ ä¸Šä¼  {filename}...")
    with open(filepath, 'rb') as f:
        data = f.read()
    boundary = 'Boundary' + ''.join(random.choices('0123456789', k=16))
    body = (
        f'--{boundary}\r\n'
        f'Content-Disposition: form-data; name="image"; filename="{filename}"\r\n'
        f'Content-Type: application/octet-stream\r\n\r\n'
    ).encode() + data + f'\r\n--{boundary}--\r\n'.encode()
    req = request.Request(f"{BASE_URL}/upload/image", data=body,
        headers={'Content-Type': f'multipart/form-data; boundary={boundary}'})
    with request.urlopen(req, timeout=30) as resp:
        result = json.loads(resp.read())
        print(f"   âœ… {result.get('name')}")
        return result.get('name')

def main():
    print("=" * 70)
    print("LTX-2 ç«–å±æµ‹è¯• (Portrait Mode)")
    print("736x1280 @ 30fps, 297å¸§, 9.9ç§’")
    print("=" * 70)

    print("\nğŸ“ æ­¥éª¤ 1/3: ä¸Šä¼ æ–‡ä»¶...")
    image_name = upload_file('/workspace/ltx_test/test_input.jpg')
    audio_name = upload_file('/workspace/ltx_test/test_audio.mp3')

    print("\nğŸ”§ æ­¥éª¤ 2/3: åŠ è½½ç«–å±å·¥ä½œæµ...")

    # åŠ è½½ç”Ÿæˆçš„ç«–å±workflow
    with open('/workspace/ltx_test/workflow_portrait_test.json') as f:
        workflow = json.load(f)

    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥æ›¿æ¢å ä½ç¬¦
    workflow_str = json.dumps(workflow)

    seed = random.randint(0, 2**48)

    # æ›¿æ¢å ä½ç¬¦
    replacements = {
        'INPUT_IMAGE': image_name,
        'INPUT_AUDIO': audio_name,
        'PROMPT_POSITIVE': 'A person speaks naturally in portrait mode, vertical video',
        'PROMPT_NEGATIVE': 'blurry, low quality, horizontal, landscape',
        'SEED': str(seed),
        'WIDTH': '736',
        'HEIGHT': '1280',
        'NUM_FRAMES': '297',
        'FPS': '30',
        'AUDIO_DURATION': '10',
        'STEPS': '8',
        'CFG_SCALE': '1.0',
        'LORA_DISTILLED_STRENGTH': '0.6',
        'LORA_DETAILER_STRENGTH': '1.0',
        'LORA_CAMERA_STRENGTH': '0.5'
    }

    for key, value in replacements.items():
        workflow_str = workflow_str.replace(key, value)

    workflow = json.loads(workflow_str)

    print("   ğŸ“± ç«–å±åˆ†è¾¨ç‡: 736x1280")
    print("   ğŸ¬ å¸§æ•°: 297å¸§ @ 30fps = 9.9ç§’")
    print("   ğŸµ éŸ³é¢‘: 10ç§’")
    print("   âš™ï¸  img_compression: 20")
    print("   ğŸ’¾ tile_size: 640, overlap: 80")

    print("\nğŸš€ æ­¥éª¤ 3/3: æäº¤å·¥ä½œæµ...")
    payload = {"prompt": workflow, "client_id": f"portrait_test_{int(time.time())}"}
    req = request.Request(f"{BASE_URL}/prompt",
        data=json.dumps(payload).encode(),
        headers={'Content-Type': 'application/json'})

    try:
        with request.urlopen(req, timeout=30) as resp:
            result = json.loads(resp.read())
            if 'error' in result:
                print(f"\nâŒ é”™è¯¯:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return None

            prompt_id = result.get('prompt_id')
            print(f"âœ… å·²æäº¤! ID: {prompt_id}")
            print("\n" + "=" * 70)
            print("ğŸ“± ç«–å±è§†é¢‘ç”Ÿæˆä¸­...")
            print("=" * 70)
            print(f"\nâ±ï¸  é¢„è®¡: ~7åˆ†é’Ÿ")
            print(f"ğŸ“ è¾“å‡º: /workspace/ComfyUI/output/ltx2_output_*.mp4")
            print(f"ğŸ“ åˆ†è¾¨ç‡: 736x1280 (ç«–å±9:16)")
            print(f"ğŸ’¾ é¢„è®¡å¤§å°: ~5-6MB")
            print(f"\nâš ï¸  éªŒè¯ç‚¹:")
            print(f"   - ç«–å±æ–¹å‘æ­£ç¡®")
            print(f"   - å£å‹åŒæ­¥å®Œç¾")
            print(f"   - è´¨é‡ä¸æ¨ªå±ç›¸å½“")
            print("\n" + "=" * 70)

            return prompt_id

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
